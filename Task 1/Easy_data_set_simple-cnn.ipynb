{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T18:50:34.932462Z",
     "iopub.status.busy": "2025-02-06T18:50:34.932090Z",
     "iopub.status.idle": "2025-02-06T18:50:34.951614Z",
     "shell.execute_reply": "2025-02-06T18:50:34.950597Z",
     "shell.execute_reply.started": "2025-02-06T18:50:34.932432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 100\n",
    "IMG_SIZE = (128, 64)  # Resizing the image\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_LABELS = 100  # Pick 100 random labels\n",
    "\n",
    "# Load dataset filenames\n",
    "dataset_path = '/kaggle/input/precogtask-easy/easy_captcha_dataset'\n",
    "all_files = [f for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
    "random.shuffle(all_files)\n",
    "selected_files = all_files[:NUM_LABELS]  # Pick 100 random images\n",
    "label_to_index = {f.split('_')[1]: i for i, f in enumerate(selected_files)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T18:50:37.511233Z",
     "iopub.status.busy": "2025-02-06T18:50:37.510910Z",
     "iopub.status.idle": "2025-02-06T18:50:37.517655Z",
     "shell.execute_reply": "2025-02-06T18:50:37.516707Z",
     "shell.execute_reply.started": "2025-02-06T18:50:37.511208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def encode_label(text):\n",
    "    \"\"\"Convert text label to a numerical class index.\"\"\"\n",
    "    return torch.tensor(label_to_index[text], dtype=torch.long, device=device)\n",
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, root, files, transform=None):\n",
    "        self.root = root\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_text = img_name.split('_')[1]  # Extract text from filename\n",
    "        image = Image.open(os.path.join(self.root, img_name)).convert('L')  # Convert to grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = encode_label(label_text)\n",
    "        return image.to(device), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T18:50:37.754562Z",
     "iopub.status.busy": "2025-02-06T18:50:37.754222Z",
     "iopub.status.idle": "2025-02-06T18:50:37.759669Z",
     "shell.execute_reply": "2025-02-06T18:50:37.758656Z",
     "shell.execute_reply.started": "2025-02-06T18:50:37.754498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = CaptchaDataset(dataset_path, selected_files, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T18:50:38.122705Z",
     "iopub.status.busy": "2025-02-06T18:50:38.122331Z",
     "iopub.status.idle": "2025-02-06T18:50:38.129932Z",
     "shell.execute_reply": "2025-02-06T18:50:38.129051Z",
     "shell.execute_reply.started": "2025-02-06T18:50:38.122676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, 1, IMG_SIZE[1], IMG_SIZE[0])  # (batch, channels, height, width)\n",
    "            sample_output = self.conv_layers(sample_input)\n",
    "            self.flattened_size = sample_output.view(1, -1).shape[1]\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flattened_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, NUM_LABELS)  # Predict one of 100 labels\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x  # Output is a class index prediction\n",
    "\n",
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T18:50:39.681761Z",
     "iopub.status.busy": "2025-02-06T18:50:39.681394Z",
     "iopub.status.idle": "2025-02-06T18:51:31.958726Z",
     "shell.execute_reply": "2025-02-06T18:51:31.957727Z",
     "shell.execute_reply.started": "2025-02-06T18:50:39.681730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 4.6056, Accuracy: 1.00%\n",
      "Epoch [2/200], Loss: 4.6295, Accuracy: 1.00%\n",
      "Epoch [3/200], Loss: 4.6063, Accuracy: 1.00%\n",
      "Epoch [4/200], Loss: 4.6061, Accuracy: 1.00%\n",
      "Epoch [5/200], Loss: 4.6053, Accuracy: 1.00%\n",
      "Epoch [6/200], Loss: 4.6048, Accuracy: 1.00%\n",
      "Epoch [7/200], Loss: 4.6044, Accuracy: 1.00%\n",
      "Epoch [8/200], Loss: 4.6040, Accuracy: 1.00%\n",
      "Epoch [9/200], Loss: 4.6035, Accuracy: 1.00%\n",
      "Epoch [10/200], Loss: 4.6028, Accuracy: 1.00%\n",
      "Epoch [11/200], Loss: 4.6017, Accuracy: 2.00%\n",
      "Epoch [12/200], Loss: 4.6001, Accuracy: 2.00%\n",
      "Epoch [13/200], Loss: 4.5978, Accuracy: 3.00%\n",
      "Epoch [14/200], Loss: 4.5946, Accuracy: 5.00%\n",
      "Epoch [15/200], Loss: 4.5902, Accuracy: 6.00%\n",
      "Epoch [16/200], Loss: 4.5841, Accuracy: 5.00%\n",
      "Epoch [17/200], Loss: 4.5746, Accuracy: 2.00%\n",
      "Epoch [18/200], Loss: 4.5610, Accuracy: 3.00%\n",
      "Epoch [19/200], Loss: 4.5417, Accuracy: 4.00%\n",
      "Epoch [20/200], Loss: 4.5147, Accuracy: 4.00%\n",
      "Epoch [21/200], Loss: 4.4765, Accuracy: 5.00%\n",
      "Epoch [22/200], Loss: 4.4281, Accuracy: 4.00%\n",
      "Epoch [23/200], Loss: 4.3626, Accuracy: 3.00%\n",
      "Epoch [24/200], Loss: 4.2845, Accuracy: 2.00%\n",
      "Epoch [25/200], Loss: 4.2408, Accuracy: 4.00%\n",
      "Epoch [26/200], Loss: 4.1216, Accuracy: 10.00%\n",
      "Epoch [27/200], Loss: 4.0364, Accuracy: 14.00%\n",
      "Epoch [28/200], Loss: 3.9403, Accuracy: 13.00%\n",
      "Epoch [29/200], Loss: 3.8307, Accuracy: 15.00%\n",
      "Epoch [30/200], Loss: 3.7346, Accuracy: 26.00%\n",
      "Epoch [31/200], Loss: 3.6969, Accuracy: 13.00%\n",
      "Epoch [32/200], Loss: 3.5476, Accuracy: 26.00%\n",
      "Epoch [33/200], Loss: 3.4262, Accuracy: 33.00%\n",
      "Epoch [34/200], Loss: 3.3577, Accuracy: 29.00%\n",
      "Epoch [35/200], Loss: 3.2334, Accuracy: 33.00%\n",
      "Epoch [36/200], Loss: 3.0895, Accuracy: 48.00%\n",
      "Epoch [37/200], Loss: 2.9694, Accuracy: 50.00%\n",
      "Epoch [38/200], Loss: 2.8767, Accuracy: 37.00%\n",
      "Epoch [39/200], Loss: 2.8883, Accuracy: 23.00%\n",
      "Epoch [40/200], Loss: 2.6882, Accuracy: 31.00%\n",
      "Epoch [41/200], Loss: 2.4993, Accuracy: 55.00%\n",
      "Epoch [42/200], Loss: 2.4358, Accuracy: 56.00%\n",
      "Epoch [43/200], Loss: 2.3588, Accuracy: 42.00%\n",
      "Epoch [44/200], Loss: 2.2735, Accuracy: 38.00%\n",
      "Epoch [45/200], Loss: 2.1143, Accuracy: 56.00%\n",
      "Epoch [46/200], Loss: 1.9742, Accuracy: 64.00%\n",
      "Epoch [47/200], Loss: 1.9144, Accuracy: 68.00%\n",
      "Epoch [48/200], Loss: 1.8270, Accuracy: 57.00%\n",
      "Epoch [49/200], Loss: 1.8509, Accuracy: 47.00%\n",
      "Epoch [50/200], Loss: 1.7950, Accuracy: 54.00%\n",
      "Epoch [51/200], Loss: 1.6089, Accuracy: 61.00%\n",
      "Epoch [52/200], Loss: 1.5182, Accuracy: 65.00%\n",
      "Epoch [53/200], Loss: 1.4657, Accuracy: 65.00%\n",
      "Epoch [54/200], Loss: 1.4138, Accuracy: 63.00%\n",
      "Epoch [55/200], Loss: 1.2489, Accuracy: 72.00%\n",
      "Epoch [56/200], Loss: 1.1759, Accuracy: 71.00%\n",
      "Epoch [57/200], Loss: 1.0973, Accuracy: 78.00%\n",
      "Epoch [58/200], Loss: 1.0496, Accuracy: 77.00%\n",
      "Epoch [59/200], Loss: 0.9359, Accuracy: 80.00%\n",
      "Epoch [60/200], Loss: 0.8705, Accuracy: 82.00%\n",
      "Epoch [61/200], Loss: 0.7652, Accuracy: 90.00%\n",
      "Epoch [62/200], Loss: 0.7292, Accuracy: 88.00%\n",
      "Epoch [63/200], Loss: 0.6491, Accuracy: 91.00%\n",
      "Epoch [64/200], Loss: 0.5881, Accuracy: 96.00%\n",
      "Epoch [65/200], Loss: 0.5469, Accuracy: 94.00%\n",
      "Epoch [66/200], Loss: 0.4946, Accuracy: 97.00%\n",
      "Epoch [67/200], Loss: 0.4442, Accuracy: 98.00%\n",
      "Epoch [68/200], Loss: 0.3814, Accuracy: 98.00%\n",
      "Epoch [69/200], Loss: 0.3564, Accuracy: 99.00%\n",
      "Epoch [70/200], Loss: 0.3098, Accuracy: 99.00%\n",
      "Epoch [71/200], Loss: 0.2842, Accuracy: 99.00%\n",
      "Epoch [72/200], Loss: 0.2485, Accuracy: 100.00%\n",
      "Epoch [73/200], Loss: 0.2326, Accuracy: 99.00%\n",
      "Epoch [74/200], Loss: 0.2063, Accuracy: 99.00%\n",
      "Epoch [75/200], Loss: 0.1777, Accuracy: 99.00%\n",
      "Epoch [76/200], Loss: 0.1638, Accuracy: 100.00%\n",
      "Epoch [77/200], Loss: 0.1450, Accuracy: 100.00%\n",
      "Epoch [78/200], Loss: 0.1357, Accuracy: 100.00%\n",
      "Epoch [79/200], Loss: 0.1186, Accuracy: 100.00%\n",
      "Epoch [80/200], Loss: 0.1100, Accuracy: 100.00%\n",
      "Epoch [81/200], Loss: 0.0952, Accuracy: 100.00%\n",
      "Epoch [82/200], Loss: 0.0853, Accuracy: 100.00%\n",
      "Epoch [83/200], Loss: 0.0793, Accuracy: 100.00%\n",
      "Epoch [84/200], Loss: 0.0720, Accuracy: 100.00%\n",
      "Epoch [85/200], Loss: 0.0651, Accuracy: 100.00%\n",
      "Epoch [86/200], Loss: 0.0583, Accuracy: 100.00%\n",
      "Epoch [87/200], Loss: 0.0553, Accuracy: 100.00%\n",
      "Epoch [88/200], Loss: 0.0492, Accuracy: 100.00%\n",
      "Epoch [89/200], Loss: 0.0460, Accuracy: 100.00%\n",
      "Epoch [90/200], Loss: 0.0418, Accuracy: 100.00%\n",
      "Epoch [91/200], Loss: 0.0396, Accuracy: 100.00%\n",
      "Epoch [92/200], Loss: 0.0356, Accuracy: 100.00%\n",
      "Epoch [93/200], Loss: 0.0335, Accuracy: 100.00%\n",
      "Epoch [94/200], Loss: 0.0308, Accuracy: 100.00%\n",
      "Epoch [95/200], Loss: 0.0291, Accuracy: 100.00%\n",
      "Epoch [96/200], Loss: 0.0270, Accuracy: 100.00%\n",
      "Epoch [97/200], Loss: 0.0255, Accuracy: 100.00%\n",
      "Epoch [98/200], Loss: 0.0241, Accuracy: 100.00%\n",
      "Epoch [99/200], Loss: 0.0229, Accuracy: 100.00%\n",
      "Epoch [100/200], Loss: 0.0215, Accuracy: 100.00%\n",
      "Epoch [101/200], Loss: 0.0204, Accuracy: 100.00%\n",
      "Epoch [102/200], Loss: 0.0191, Accuracy: 100.00%\n",
      "Epoch [103/200], Loss: 0.0183, Accuracy: 100.00%\n",
      "Epoch [104/200], Loss: 0.0175, Accuracy: 100.00%\n",
      "Epoch [105/200], Loss: 0.0166, Accuracy: 100.00%\n",
      "Epoch [106/200], Loss: 0.0159, Accuracy: 100.00%\n",
      "Epoch [107/200], Loss: 0.0152, Accuracy: 100.00%\n",
      "Epoch [108/200], Loss: 0.0145, Accuracy: 100.00%\n",
      "Epoch [109/200], Loss: 0.0140, Accuracy: 100.00%\n",
      "Epoch [110/200], Loss: 0.0134, Accuracy: 100.00%\n",
      "Epoch [111/200], Loss: 0.0129, Accuracy: 100.00%\n",
      "Epoch [112/200], Loss: 0.0125, Accuracy: 100.00%\n",
      "Epoch [113/200], Loss: 0.0120, Accuracy: 100.00%\n",
      "Epoch [114/200], Loss: 0.0116, Accuracy: 100.00%\n",
      "Epoch [115/200], Loss: 0.0112, Accuracy: 100.00%\n",
      "Epoch [116/200], Loss: 0.0109, Accuracy: 100.00%\n",
      "Epoch [117/200], Loss: 0.0106, Accuracy: 100.00%\n",
      "Epoch [118/200], Loss: 0.0102, Accuracy: 100.00%\n",
      "Epoch [119/200], Loss: 0.0100, Accuracy: 100.00%\n",
      "Epoch [120/200], Loss: 0.0097, Accuracy: 100.00%\n",
      "Epoch [121/200], Loss: 0.0094, Accuracy: 100.00%\n",
      "Epoch [122/200], Loss: 0.0091, Accuracy: 100.00%\n",
      "Epoch [123/200], Loss: 0.0089, Accuracy: 100.00%\n",
      "Epoch [124/200], Loss: 0.0087, Accuracy: 100.00%\n",
      "Epoch [125/200], Loss: 0.0085, Accuracy: 100.00%\n",
      "Epoch [126/200], Loss: 0.0083, Accuracy: 100.00%\n",
      "Epoch [127/200], Loss: 0.0081, Accuracy: 100.00%\n",
      "Epoch [128/200], Loss: 0.0079, Accuracy: 100.00%\n",
      "Epoch [129/200], Loss: 0.0077, Accuracy: 100.00%\n",
      "Epoch [130/200], Loss: 0.0076, Accuracy: 100.00%\n",
      "Epoch [131/200], Loss: 0.0074, Accuracy: 100.00%\n",
      "Epoch [132/200], Loss: 0.0072, Accuracy: 100.00%\n",
      "Epoch [133/200], Loss: 0.0071, Accuracy: 100.00%\n",
      "Epoch [134/200], Loss: 0.0069, Accuracy: 100.00%\n",
      "Epoch [135/200], Loss: 0.0068, Accuracy: 100.00%\n",
      "Epoch [136/200], Loss: 0.0067, Accuracy: 100.00%\n",
      "Epoch [137/200], Loss: 0.0065, Accuracy: 100.00%\n",
      "Epoch [138/200], Loss: 0.0064, Accuracy: 100.00%\n",
      "Epoch [139/200], Loss: 0.0063, Accuracy: 100.00%\n",
      "Epoch [140/200], Loss: 0.0062, Accuracy: 100.00%\n",
      "Epoch [141/200], Loss: 0.0061, Accuracy: 100.00%\n",
      "Epoch [142/200], Loss: 0.0060, Accuracy: 100.00%\n",
      "Epoch [143/200], Loss: 0.0059, Accuracy: 100.00%\n",
      "Epoch [144/200], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [145/200], Loss: 0.0057, Accuracy: 100.00%\n",
      "Epoch [146/200], Loss: 0.0056, Accuracy: 100.00%\n",
      "Epoch [147/200], Loss: 0.0055, Accuracy: 100.00%\n",
      "Epoch [148/200], Loss: 0.0054, Accuracy: 100.00%\n",
      "Epoch [149/200], Loss: 0.0053, Accuracy: 100.00%\n",
      "Epoch [150/200], Loss: 0.0052, Accuracy: 100.00%\n",
      "Epoch [151/200], Loss: 0.0052, Accuracy: 100.00%\n",
      "Epoch [152/200], Loss: 0.0051, Accuracy: 100.00%\n",
      "Epoch [153/200], Loss: 0.0050, Accuracy: 100.00%\n",
      "Epoch [154/200], Loss: 0.0049, Accuracy: 100.00%\n",
      "Epoch [155/200], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [156/200], Loss: 0.0048, Accuracy: 100.00%\n",
      "Epoch [157/200], Loss: 0.0047, Accuracy: 100.00%\n",
      "Epoch [158/200], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [159/200], Loss: 0.0046, Accuracy: 100.00%\n",
      "Epoch [160/200], Loss: 0.0045, Accuracy: 100.00%\n",
      "Epoch [161/200], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [162/200], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [163/200], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [164/200], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [165/200], Loss: 0.0042, Accuracy: 100.00%\n",
      "Epoch [166/200], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [167/200], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [168/200], Loss: 0.0040, Accuracy: 100.00%\n",
      "Epoch [169/200], Loss: 0.0039, Accuracy: 100.00%\n",
      "Epoch [170/200], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [171/200], Loss: 0.0038, Accuracy: 100.00%\n",
      "Epoch [172/200], Loss: 0.0037, Accuracy: 100.00%\n",
      "Epoch [173/200], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [174/200], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [175/200], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [176/200], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [177/200], Loss: 0.0034, Accuracy: 100.00%\n",
      "Epoch [178/200], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [179/200], Loss: 0.0033, Accuracy: 100.00%\n",
      "Epoch [180/200], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [181/200], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [182/200], Loss: 0.0031, Accuracy: 100.00%\n",
      "Epoch [183/200], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [184/200], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [185/200], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [186/200], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [187/200], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [188/200], Loss: 0.0027, Accuracy: 100.00%\n",
      "Epoch [189/200], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [190/200], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [191/200], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [192/200], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [193/200], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [194/200], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [195/200], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [196/200], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [197/200], Loss: 0.0021, Accuracy: 100.00%\n",
      "Epoch [198/200], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [199/200], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [200/200], Loss: 0.0019, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Initialize lists for tracking evolution\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(EPOCHS):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)  # CrossEntropyLoss expects class indices\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Accumulate predictions and true labels\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "    accuracy = 100 * correct / total\n",
    "    epoch_losses.append(loss.item())\n",
    "    epoch_accuracies.append(accuracy)\n",
    "    \n",
    "    # Compute metrics\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    logging.info(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")\n",
    "    logging.info(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Plot evolution of loss and accuracy\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epoch_losses, label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epoch_accuracies, label='Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NEW CELL: Example Predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_images, sample_labels = next(iter(dataloader))\n",
    "    sample_images = sample_images.to(device)\n",
    "    outputs = model(sample_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    # Invert the label_to_index mapping\n",
    "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "    for i in range(min(5, sample_images.size(0))):\n",
    "        true_label = index_to_label[sample_labels[i].item()]\n",
    "        pred_label = index_to_label.get(predicted[i].item(), \"Unknown\")\n",
    "        print(f\"Sample {i+1}: True Label: {true_label} | Predicted: {pred_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6595659,
     "sourceId": 10651525,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
